set $cache_key $scheme://$host$request_uri;

# ignore requests destined for the cache which are POST, PUT, DELETE, etc.
limit_except GET HEAD {
    deny all;
}

open_file_cache off;

proxy_cache            PROXY_CACHE;

# https://cassiomolin.com/2016/09/09/which-http-status-codes-are-cacheable/
proxy_cache_valid  200 301 302 400 404  1y;

# we want to cache everything, even if cache-control says not to
# it's important to ignore the vary header from upstream otherwise
# nginx will cache multiple copies of the same page
proxy_ignore_headers Cache-Control Expires Set-Cookie Vary;

# Don't pass conditional headers to upstream (we want cachable reponses only)
proxy_set_header If-None-Match "";
proxy_set_header If-Modified-Since "";

proxy_cache_key $cache_key;
proxy_cache_use_stale error timeout invalid_header updating http_500 http_502 http_503 http_504;

#  When enabled, only one request at a time will be allowed to populate a new cache element identified according to the proxy_cache_key directive by passing a request to a proxied server. 
# I added this to avoid 'cache stampede' issues overwhelming the upstream for heavily trafficked sites
proxy_cache_lock on;

# Fine-tune timeouts for better failover
proxy_connect_timeout 3s;  # Time to establish a connection to the upstream
proxy_send_timeout 10s;    # Time to send the request to the upstream
proxy_read_timeout 15s;    # Time to read the response from the upstream

{{> reverse-proxy-base.conf}}

# This registers a cached response in our dictionary of cached responses
# pass in the proxy_cache_key setting
log_by_lua_block {
    if ngx.var.upstream_cache_status == "MISS" then
        cacher:add(ngx.var.host, ngx.var.cache_key)
    end
}
